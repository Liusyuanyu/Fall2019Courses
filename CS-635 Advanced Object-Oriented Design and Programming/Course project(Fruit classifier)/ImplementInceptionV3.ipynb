{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the packages and function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Dropout\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "import numpy as np\n",
    "import keras.backend as k\n",
    "from keras.optimizers import RMSprop \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data (Old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "del fruit_x\n",
    "del fruit_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_x=[]\n",
    "fruit_y=[]\n",
    "\n",
    "# labels =['Apple', 'Avocado','Cherry','Kiwi','Kumquats', 'Lemon']\n",
    "\n",
    "# path = '.\\\\Training'\n",
    "# path = '.\\\\SamllTrain'\n",
    "# path = '.\\\\SamllTrain_50'\n",
    "path = '.\\\\LessImageTrain'\n",
    "labels = listdir(path)\n",
    "\n",
    "for labelName in labels:\n",
    "    file_path = join(path,labelName)\n",
    "    image_names = listdir(file_path)\n",
    "    for aimage in image_names:\n",
    "        image_path = join(file_path,aimage)\n",
    "#         if(os.path.exists(image_path)):\n",
    "#         train_image = load_img(image_path,color_mode = \"grayscale\")  # GrayScale\n",
    "        train_image = load_img(image_path)  # RGB Image\n",
    "\n",
    "        train_image = img_to_array(train_image)  # this is a Numpy array with shape (3, 150, 150)\n",
    "        fruit_x.append(train_image)\n",
    "        fruit_y.append(labelName)\n",
    "        \n",
    "fruit_x_ori= fruit_x.copy()\n",
    "fruit_y_ori= fruit_y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fruit_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'fruit_x' in locals():\n",
    "    del fruit_x\n",
    "if 'fruit_y' in locals():\n",
    "    del fruit_y\n",
    "    \n",
    "fruit_x= fruit_x_ori\n",
    "fruit_y= fruit_y_ori\n",
    "\n",
    "fruit_x = np.asarray(fruit_x)/255\n",
    "\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(fruit_y)\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False,categories='auto')\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "fruit_y = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "num_class = len(labels)\n",
    "input_shape = fruit_x[0].shape\n",
    "\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(fruit_x, fruit_y, test_size=0.2,shuffle = True,random_state=1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(fruit_x, fruit_y, test_size=0.2,shuffle = True)\n",
    "# X_train = np.asarray(X_train)\n",
    "# X_test = np.asarray(X_test)\n",
    "\n",
    "# X_train = X_train.astype('float32')\n",
    "# X_test = X_test.astype('float32')\n",
    "# X_train /= 255\n",
    "# X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3200"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input_shape\n",
    "len(X_train)\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, Y_train, Y_test = train_test_split(fruit_x, fruit_y, test_size=0.2,shuffle = True,random_state=1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(fruit_x, fruit_y, test_size=0.3,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "810"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=[]\n",
    "Y_train=[]\n",
    "\n",
    "path_train = '.\\\\LessImageTrain'\n",
    "labels = listdir(path_train)\n",
    "\n",
    "for labelName in labels:\n",
    "    file_path = join(path_train,labelName)\n",
    "    image_names = listdir(file_path)\n",
    "    for aimage in image_names:\n",
    "        image_path = join(file_path,aimage)\n",
    "        train_image = load_img(image_path)  # RGB Image\n",
    "\n",
    "        train_image = img_to_array(train_image)  # this is a Numpy array with shape (3, 150, 150)\n",
    "        X_train.append(train_image)\n",
    "        Y_train.append(labelName)\n",
    "\n",
    "X_test=[]\n",
    "Y_test=[]\n",
    "path_test = '.\\\\LessImageTest'\n",
    "labels = listdir(path_train)\n",
    "for labelName in labels:\n",
    "    file_path = join(path_test,labelName)\n",
    "    image_names = listdir(file_path)\n",
    "    for aimage in image_names:\n",
    "        image_path = join(file_path,aimage)\n",
    "        train_image = load_img(image_path)  # RGB Image\n",
    "\n",
    "        train_image = img_to_array(train_image)  # this is a Numpy array with shape (3, 150, 150)\n",
    "        X_test.append(train_image)\n",
    "        Y_test.append(labelName)        \n",
    "\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(Y_train)\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False,categories='auto')\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "Y_train = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "integer_encoded = label_encoder.fit_transform(Y_test)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "Y_test = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "\n",
    "num_class = len(labels)\n",
    "input_shape = X_train[0].shape\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the InceptionV3 Model(Keras) Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the base pre-trained model\n",
    "def build_model(nb_classes, inputs_shape):\n",
    "    k.clear_session()\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False,input_shape=inputs_shape)\n",
    "    \n",
    "    # add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(nb_classes, activation='softmax')(x)\n",
    "#     x = Dropout(0.5)(x)\n",
    "\n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolutional InceptionV3 layers\n",
    "    for layer in base_model.layers[:249]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model.layers[249:]:\n",
    "        layer.trainable = True\n",
    "    count = 0\n",
    "    for layer in base_model.layers:\n",
    "        if ('batch_normalization' in layer.name):\n",
    "            count +=1\n",
    "            layer.trainable =True\n",
    "            if(count>=19):\n",
    "                break\n",
    "        \n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # compile the model (should be done *after* setting layers to non-trainable)\n",
    "    print (\"starting model compile\")\n",
    "    compile(model)\n",
    "    print (\"model compile done\")\n",
    "    return model\n",
    "\n",
    "def compile(model):\n",
    "    model.compile(optimizer=RMSprop(lr=0.001), loss='categorical_crossentropy', metrics=[\"accuracy\"])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting model compile\n",
      "model compile done\n"
     ]
    }
   ],
   "source": [
    "model = build_model(num_class, input_shape)\n",
    "# model = build_model(81, [100,100,3])\n",
    "# # model.summary()\n",
    "# print(\"\\n===============================\\n The trainable layers:\")\n",
    "# for layer in model.trainable_weights:\n",
    "#     print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5083 samples, validate on 1017 samples\n",
      "Epoch 1/5\n",
      "5083/5083 [==============================] - 364s 72ms/step - loss: 0.0317 - accuracy: 0.9982 - val_loss: 3.9498 - val_accuracy: 0.6067\n",
      "Epoch 2/5\n",
      "5083/5083 [==============================] - 364s 72ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 3.1317 - val_accuracy: 0.6431\n",
      "Epoch 3/5\n",
      "5083/5083 [==============================] - 359s 71ms/step - loss: 3.6843e-06 - accuracy: 1.0000 - val_loss: 3.5866 - val_accuracy: 0.6382\n",
      "Epoch 4/5\n",
      "5083/5083 [==============================] - 360s 71ms/step - loss: 0.0108 - accuracy: 0.9986 - val_loss: 2.3622 - val_accuracy: 0.6804\n",
      "Epoch 5/5\n",
      "5083/5083 [==============================] - 360s 71ms/step - loss: 0.0776 - accuracy: 0.9990 - val_loss: 2.5933 - val_accuracy: 0.7522\n",
      "Test loss: 2.5932667785220676\n",
      "Test accuracy: 0.752212405204773\n"
     ]
    }
   ],
   "source": [
    "# epochs = 30\n",
    "epochs = 5\n",
    "batch_size = 100\n",
    "\n",
    "history=model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x211644bd088>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.title('Loss')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save(model, 'model_100images')\n",
    "# # model.save('model_Allimages.h5')\n",
    "# model.save('model_300images.h5')\n",
    "# model.save('./ModelBox/model_SamllTrain.h5')\n",
    "# model.save('./ModelBox/Fruit_3Classes.h5')\n",
    "model.save('./ModelBox/Fruit_10Classes.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.735868464814568, 0.7509344816207886]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from keras.preprocessing.image import array_to_img\n",
    "\n",
    "# X_train[0]*=255\n",
    "# X_train[0]\n",
    "# array_to_img(X_train[100]*255)\n",
    "# len(X_train)\n",
    "model.evaluate(X_train, Y_train, verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BackUp codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "810"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=[]\n",
    "Y_test=[]\n",
    "path_test = '.\\\\LessImageTest'\n",
    "labels = listdir(path_train)\n",
    "for labelName in labels:\n",
    "    file_path = join(path_test,labelName)\n",
    "    image_names = listdir(file_path)\n",
    "    for aimage in image_names:\n",
    "        image_path = join(file_path,aimage)\n",
    "        train_image = load_img(image_path)  # RGB Image\n",
    "\n",
    "        train_image = img_to_array(train_image)  # this is a Numpy array with shape (3, 150, 150)\n",
    "        X_test.append(train_image)\n",
    "        Y_test.append(labelName)        \n",
    "\n",
    "integer_encoded = label_encoder.fit_transform(Y_test)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "Y_test = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "X_test = np.asarray(X_test)\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255\n",
    "\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# # add a global spatial average pooling layer\n",
    "# x = base_model.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# # let's add a fully-connected layer\n",
    "# x = Dense(1024, activation='relu')(x)\n",
    "# # and a logistic layer -- let's say we have 200 classes\n",
    "# predictions = Dense(6, activation='softmax')(x)\n",
    "\n",
    "# # this is the model we will train\n",
    "# model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# # first: train only the top layers (which were randomly initialized)\n",
    "# # i.e. freeze all convolutional InceptionV3 layers\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# # compile the model (should be done *after* setting layers to non-trainable)\n",
    "# model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "# # train the model on the new data for a few epochs\n",
    "# model.fit_generator(...)\n",
    "\n",
    "# # at this point, the top layers are well trained and we can start fine-tuning\n",
    "# # convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# # and train the remaining top layers.\n",
    "\n",
    "# # let's visualize layer names and layer indices to see how many layers\n",
    "# # we should freeze:\n",
    "# for i, layer in enumerate(base_model.layers):\n",
    "#    print(i, layer.name)\n",
    "\n",
    "# # we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# # the first 249 layers and unfreeze the rest:\n",
    "# for layer in model.layers[:249]:\n",
    "#    layer.trainable = False\n",
    "# for layer in model.layers[249:]:\n",
    "#    layer.trainable = True\n",
    "\n",
    "# # we need to recompile the model for these modifications to take effect\n",
    "# # we use SGD with a low learning rate\n",
    "# from keras.optimizers import SGD\n",
    "# model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')\n",
    "\n",
    "# # we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# # alongside the top Dense layers\n",
    "# model.fit_generator(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Images from original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "path = '.\\\\Training'\n",
    "smallPath = '.\\\\LessImageTrain'\n",
    "labels_list = listdir(path)\n",
    "\n",
    "for labelName in labels_list:\n",
    "    tmp_path = join(smallPath,labelName)\n",
    "    if(not os.path.exists( tmp_path)):\n",
    "        os.mkdir(tmp_path)\n",
    "\n",
    "    ori_path = join(path,labelName)\n",
    "    new_path = join(smallPath,labelName)\n",
    "    \n",
    "    image_names = listdir(ori_path)\n",
    "    image_num =0\n",
    "    \n",
    "    randonIndex =  np.random.choice(len(image_names),200, replace=False)\n",
    "    for ind in randonIndex:\n",
    "        image_num +=1\n",
    "        shutil.copyfile(join(ori_path,image_names[ind]),join(new_path,image_names[ind]))\n",
    "    \n",
    "    \n",
    "#     for ind in range(0,len(image_names),5):\n",
    "#         image_num +=1\n",
    "#         shutil.copyfile(join(ori_path,image_names[ind]),join(new_path,image_names[ind]))\n",
    "#         if(image_num==100):\n",
    "#             break\n",
    "\n",
    "# labels_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read partial categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_train' in locals():\n",
    "    del X_train\n",
    "if 'Y_train' in locals():\n",
    "    del Y_train\n",
    "if 'X_test' in locals():\n",
    "    del X_test\n",
    "if 'Y_test' in locals():\n",
    "    del Y_test\n",
    "if 'model' in locals():\n",
    "    del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=[]\n",
    "Y_train=[]\n",
    "\n",
    "# path_train = '.\\\\LatestData\\Training'\n",
    "path_train = '.\\\\Fruits\\\\Training'\n",
    "labels = listdir(path_train)\n",
    "\n",
    "num_class = 10\n",
    "\n",
    "randonIndex =  np.random.choice(len(labels),num_class, replace=False)\n",
    "\n",
    "for index in randonIndex:\n",
    "    file_path = join(path_train,labels[index])\n",
    "    image_names = listdir(file_path)\n",
    "    for aimage in image_names:\n",
    "        image_path = join(file_path,aimage)\n",
    "        train_image = load_img(image_path)  # RGB Image\n",
    "\n",
    "        train_image = img_to_array(train_image)  # this is a Numpy array with shape (3, 150, 150)\n",
    "        X_train.append(train_image)\n",
    "        Y_train.append(labels[index])\n",
    "\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(Y_train)\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False,categories='auto')\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "Y_train = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "\n",
    "# num_class = len(labels)\n",
    "input_shape = X_train[0].shape\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_train /= 255\n",
    "\n",
    "_, X_test, _, Y_test = train_test_split(X_train, Y_train, test_size=0.2,shuffle = True)\n",
    "\n",
    "X_train,Y_train=shuffle(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([71, 14,  3, 23, 25, 73, 62, 41, 16, 11])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randonIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(X_train)\n",
    "X_train,Y_train=shuffle(X_train,Y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
